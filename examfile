## welcome to the exam of Introduction to econometrics


cats <- read.table("/home/lorisr/exam/data/cats.txt", header = TRUE, sep = "")
cats$sex <- factor(cats$sex, levels = c("-1","1"), labels = c("F","M"))
plot(heart_weight ~ body_weight , data = cats, main="Plot of Body Weight Vs. Heart weight",
     xlab="Body weight (Kg)",ylab="Heart weight (g)", col = sex)
legend(x="topleft",legend=c("Male","Female"), pch=c(1,1),col=c("Red","Black"),bg="white")
abline(reg=lm(heart_weight ~ body_weight,data=cats[cats$sex =="F",]),col="Black",lwd=2)
abline(reg=lm(heart_weight ~ body_weight,data=cats[cats$sex =="M",]),col="Red",lwd=2)
grid()

fm <- lm(heart_weight~body_weight,data=cats)
summary(fm)

fm1 <- lm(heart_weight~body_weight+sex,data=cats)
summary(fm1)
fm2 <- lm(heart_weight~body_weight*sex,data=cats)
summary(fm2)
anova(fm, fm1, fm2)

From the anova test, by comparing the p values the first model(model) is the best model.
The p values of other models are not significant

op = par(mfrow = c(1, 3))
plot(heart_weight ~ body_weight , data = cats,xlab="Body weight (Kg)",ylab="Heart weight (g)", col = sex)
abline(reg=model,col="Black",lwd=2)

plot(heart_weight ~ body_weight , data = cats,xlab="Body weight (Kg)",ylab="Heart weight (g)", col = sex)
abline(reg=model2,col="Blue",lwd=2)

plot(heart_weight ~ body_weight , data = cats,xlab="Body weight (Kg)",ylab="Heart weight (g)", col = sex)
abline(reg=model3,col="Green",lwd=2)

par(op)

```{r, echo=FALSE, message=FALSE}
load("~/Desktop/esame/data/ac.rda")
ac$alive = 10 - ac$dec
ac$rate = ac$dec/ac$tot
```

```{r, echo=FALSE}
plot(dec ~ dose, data = ac,xlab="Dose",ylab="Deaths")
```


From the graph we can see that if the dose increase the number of death increase too, 
but the relation is not linear

```{r, echo=TRUE, eval= TRUE}
ac$alive = 10 - ac$dec
SF = cbind(ac$dec, alive = 10 - ac$dec)
gm = glm(SF ~ dose, family = binomial, data=ac)
summary(gm)
plot(ac$dose,ac$rate, xlab="Dose",ylab="Death rate",col= "red")


gm2 = glm(SF ~ dose + I(dose^2), family = binomial, data=ac)
summary(gm2)



We use the linear model to find a linear relation among two or more variable. The focus is on the relationship between a dependent variable and one or more independent variables (or "predictors"). More specifically, it helps one understand how the typical value of the dependent variable changes when any one of the independent variables is varied, while the other independent variables are held fixed. For example, when we have two variables we might want to draw a smooth line that “best approximates” the causal relation between this two variables. 
In particular, the assumption on a linear model is that the response variables have error distribuited like a normal distribution. This is the main difference with the GLM, that is necessary because the dependent variable of model is non-Normal. 
The different distribution we seen during the lesson are: Binomial, Poisson, Gamma and Gaussian. The Gaussian case with the identity function is the same of linear model.

